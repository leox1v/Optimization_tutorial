{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "# load mnist images and store them in two seperate tensorflow dataset (train and test)\n",
    "(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train, y_test = tf.cast(y_train, dtype=tf.int32), tf.cast(y_test, dtype=tf.int32)\n",
    "dset_train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(100, reshuffle_each_iteration=True).repeat().batch(batch_size)\n",
    "dset_test = tf.data.Dataset.from_tensor_slices((x_test, y_test)).shuffle(100, reshuffle_each_iteration=True).repeat().batch(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(tf.keras.Model):\n",
    "    '''We use a simple model with only one hidden fully connected layer.\n",
    "    More complex architectures can achieve higher accuracies, see http://yann.lecun.com/exdb/mnist/.'''\n",
    "    def __init__(self, units=128):\n",
    "        super(Model, self).__init__()\n",
    "        self.units = units\n",
    "        self.W1 = tf.layers.Dense(units, activation=tf.nn.relu)\n",
    "        self.W2 = tf.layers.Dense(10)\n",
    "    \n",
    "    def call(self, _input):\n",
    "        '''One forward pass of the model with a batch of MNIST images as the input x (shape: [32, 28x28x]) and \n",
    "        logits for each class label as the output (shape: [32, 10]).'''\n",
    "        x = tf.layers.flatten(_input)\n",
    "        hidden1 = self.W1(x)\n",
    "        logits = self.W2(hidden1)\n",
    "        return logits\n",
    "\n",
    "def loss(logits, labels):\n",
    "    '''Cross entropy loss between the predicted (soft) assignments and the true target labels.'''\n",
    "    return tf.reduce_mean(\n",
    "      tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "          logits=logits, labels=labels))\n",
    "\n",
    "\n",
    "def compute_accuracy(logits, labels):\n",
    "    predictions = tf.argmax(logits, axis=1, output_type=tf.int64)\n",
    "    labels = tf.cast(labels, tf.int64)\n",
    "    batch_size = int(logits.shape[0])\n",
    "    return tf.reduce_sum(\n",
    "      tf.cast(tf.equal(predictions, labels), dtype=tf.float32)) / batch_size\n",
    "\n",
    "\n",
    "def train(model, optimizer, dataset, dataset_test, log_interval=100, stop=500):\n",
    "    \"\"\"Trains model on `dataset` using `optimizer`.\"\"\"\n",
    "    start = time.time()\n",
    "    for (batch, (images, labels)) in enumerate(dataset):\n",
    "        \n",
    "        # 'tape' records operations for automatic differentiation\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(images)\n",
    "            loss_value = loss(logits, labels)\n",
    "        \n",
    "        # compute the gradients and use them to optimize the model variables\n",
    "        grads = tape.gradient(loss_value, model.variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.variables))\n",
    "        \n",
    "        if log_interval and batch % log_interval == 0:\n",
    "            rate = log_interval / (time.time() - start) if batch > 0 else 1./(time.time() - start)\n",
    "            print('Step #%d\\tLoss: %.6f (%d steps/sec)' % (batch, loss_value, rate))\n",
    "            start = time.time()\n",
    "        if batch % 100 == 0:\n",
    "            test(model, dataset_test)\n",
    "        if batch >= stop: break\n",
    "        \n",
    "def test(model, dataset):\n",
    "    \"\"\"Perform an evaluation of `model` on the examples from `dataset`.\"\"\"\n",
    "    avg_loss = 0\n",
    "    avg_accuracy = 0\n",
    "    for (images, labels) in dataset:\n",
    "        logits = model(images)\n",
    "        avg_loss = loss(logits, labels)\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits, axis=1, output_type=tf.int32),labels), tf.float32))\n",
    "        break\n",
    "    print('Test set: Average loss: {0:.3f}, Accuracy: {1:.1f}%\\n'.format(avg_loss.numpy(), 100 * accuracy.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the optimizer\n",
    "In this exercise you will implement three of the most used optimizer in deep learning from scratch: SGD, Adagrad, and Adam. This blog post (http://ruder.io/optimizing-gradient-descent/) gives a great overview over the different methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD\n",
    "$$ \n",
    "    \\theta^+ = \\theta - \\eta L(x_{i:i+n}; \\theta)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, learning_rate=0.01):\n",
    "        # TODO\n",
    "        \n",
    "    def apply_gradients(self, grads_vars):\n",
    "        # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adagrad \n",
    "$$\n",
    "    g_{t,i} = \\nabla_\\theta L(x_t; \\theta_{t,i})\\\\\n",
    "    G_{t,i} = \\sum_{\\tau=0}^t g_{\\tau, i}\\\\\n",
    "    \\theta^+ = \\theta - \\frac{\\eta}{\\sqrt{G_{t,i} + \\epsilon}} g_{t,i}\n",
    "$$\n",
    "initial_accumulator_value $:= \\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adagrad:\n",
    "    def __init__(self, learning_rate=0.001, initial_accumulator_value=0.1):\n",
    "        # TODO\n",
    "        \n",
    "    def apply_gradients(self, grads_vars):\n",
    "        # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam\n",
    "https://arxiv.org/pdf/1412.6980.pdf see improved algorithm at the end of section 2 (Different to the version explained in the referenced blogpost).\n",
    "$$\n",
    "    m_t = \\beta_1 m_{t-1} + (1-\\beta_1) \\nabla_\\theta L(x_t; \\theta_t)\\\\\n",
    "    v_t = \\beta_2 v_{t-1} + (1-\\beta_2) \\left(\\nabla_\\theta L(x_t; \\theta_t)\\right) ^2\\\\\n",
    "    \\eta_t = \\eta * \\frac{\\sqrt{1-\\beta_2^t}}{1-\\beta_1^t}\n",
    "$$\n",
    "$$\n",
    "    \\theta_{t+1} = \\theta_t - \\frac{\\eta_t}{\\sqrt{v_t} + \\epsilon}m_t\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam:\n",
    "    def __init__(self, learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08):\n",
    "        # TODO\n",
    "        \n",
    "    def apply_gradients(self, grads_vars):\n",
    "        # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a fixed random seed, so you can compare your implementation against the provided tensorflow optimizer.\n",
    "tf.set_random_seed(42)\n",
    "\n",
    "model = Model()\n",
    "\n",
    "''' Use your own implementation of the optimizer '''\n",
    "# optimizer = SGD(learning_rate=0.01)\n",
    "# optimizer = Adagrad(learning_rate=0.1)\n",
    "# optimizer = Adam(learning_rate=0.01)\n",
    "\n",
    "''' Or use a pre-built one from tensorflow. Compare your solution against these given optimizers. '''\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "# optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "# optimizer = tf.train.AdamOptimizer(learning_rate=0.01)\n",
    "\n",
    "train(model, optimizer, dset_train, dset_test, stop=500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
